{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, re\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import copy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = re.findall(r\"[\\w]+|[^\\s\\w]\", text)\n",
    "    return tokens\n",
    "\n",
    "def ngrams(n, tokens):\n",
    "    prepend_token = '<START>'\n",
    "    append_token = '<END>'\n",
    "    for i in range(n - 1):\n",
    "        tokens = [prepend_token] + tokens\n",
    "    tokens.append(append_token)\n",
    "    grams = []\n",
    "    for j in range(len(tokens)-n+1):\n",
    "        context = tuple(tokens[j:j+n-1])\n",
    "        token = tokens[j+n-1]\n",
    "        grams.append((context, token))\n",
    "    return grams\n",
    "\n",
    "class NgramModel(object):\n",
    "\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.context_counts = defaultdict(lambda:0) # frequency of context\n",
    "        self.sequence_counts = defaultdict(lambda:0) # frequency of (context, token) sequence\n",
    "\n",
    "    def update(self, sentence):\n",
    "        all_ngrams = ngrams(self.n, tokenize(sentence))\n",
    "        for (context, token) in all_ngrams:\n",
    "            self.context_counts[context] += 1 # increment the context count\n",
    "            self.sequence_counts[(context, token)] += 1 # increment the (context, token) sequence count\n",
    "\n",
    "    def prob(self, context, token):\n",
    "        denominator = self.context_counts[context] # frequency of context followed by any token\n",
    "        numerator = self.sequence_counts[(context,token)] # frequency of exact (context, token) sequence\n",
    "        prob = numerator/denominator\n",
    "        return prob\n",
    "\n",
    "    def random_token(self, context):\n",
    "        r = random.random()\n",
    "        tokens_in_context = [] # collect all tokens that share the context\n",
    "        for k, v in self.sequence_counts.items():\n",
    "            # k is a (context, token) tuple\n",
    "            # v is the count\n",
    "            if k[0] == context: # found an ngram with same context\n",
    "                tokens_in_context.append(k[1])\n",
    "        tokens_in_context = sorted(tokens_in_context) # enforce natural Pythonic ordering by sorting\n",
    "        pre_sum = 0\n",
    "        for i, token in enumerate(tokens_in_context):\n",
    "            # pre_sum = sum([self.prob(context, other_token) for other_token in tokens_in_context[:i]])\n",
    "            # pre_sum is sum of probabilities up to, but excluding, the current token\n",
    "            post_sum = pre_sum + self.prob(context, token)\n",
    "            # post_sum also includes the probability of the current token\n",
    "            if pre_sum <= r < post_sum:\n",
    "                return token\n",
    "            pre_sum = post_sum\n",
    "    \n",
    "    def random_text(self, token_count):\n",
    "        output_text = []\n",
    "        all_context = ['<START>' for i in range(self.n - 1)] # keep a running context list initialized with <START>s\n",
    "        for i in range(token_count):\n",
    "            curr_context = tuple(all_context[len(all_context)-self.n+1:]) # extract context from running context list\n",
    "            next_token = self.random_token(curr_context)\n",
    "            output_text.append(next_token)\n",
    "            if next_token == \"<END>\":\n",
    "                # if next token is <END> append multiple <START>s to the running context list\n",
    "                for i in range(self.n - 1):\n",
    "                    all_context.append('<START>')\n",
    "            else:\n",
    "                # otherwise append the latest token to the running context list\n",
    "                all_context.append(next_token)\n",
    "        return \" \".join(output_text)\n",
    "\n",
    "    def perplexity(self, sentence):\n",
    "        tokens = tokenize(sentence)\n",
    "        m = len(tokens)\n",
    "        all_ngrams = ngrams(self.n, tokens)\n",
    "        log_prob_sum = 0\n",
    "        for (context, token) in all_ngrams:\n",
    "            log_prob_sum += math.log(self.prob(context, token))\n",
    "        perplexity = math.exp(-1/(m+1) * log_prob_sum)\n",
    "        return perplexity\n",
    "\n",
    "def create_ngram_model(n, path):\n",
    "    m = NgramModel(n)\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            m.update(line)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/sppatankar/Desktop/CIS 521/Homework 8/frankenstein.txt'\n",
    "n = 20\n",
    "m = create_ngram_model(n, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" Thus I relieve thee , my creator , \" he said , and placed his hated hands before my eyes , which I flung from me with violence ; \" thus I take from thee a sight which you abhor . <END> She seemed pleased and went into the garden for some roots and plants , which she placed in water , and then upon the fire . <END> Who can describe their horror and consternation on beholding me ? <END> I had determined at one time that the memory of these evils should die with me , but you have won me to alter my determination . <END> During my youthful days discontent never visited my mind , and if I was ever overcome by ennui , the sight of what is beautiful in nature or the study of what is excellent and sublime in the productions of man could always interest my heart and communicate elasticity to my spirits . <END> No ! <END> Felix and Agatha spent more time in amusement and conversation , and were assisted in their labours by servants . <END> When I thought of my friends , of the mild voice of De Lacey , the gentle eyes of Agatha , and the exquisite beauty of the Arabian , these thoughts vanished and a gush of tears somewhat soothed me . <END> My manner as I thus addressed him was impressive but calm ; I had formed in my own heart a resolution to pursue my destroyer to death , and this purpose quieted my agony and for an interval reconciled me to life . <END> I listened to this discourse with the extremest agony . <END> The latter part of his tale had kindled anew in me the anger that had died away while he narrated his peaceful life among the cottagers , and as he said this I could no longer suppress the rage that burned within me . <END> Her mother was a German and had died on giving her birth . <END> I am about to proceed on a long and difficult voyage , the emergencies of which will demand all my fortitude : I am required not only to raise the spirits of others , but sometimes to sustain my own , when theirs are failing . <END> If thou wert yet alive and yet cherished a desire of revenge against me , it would be better satiated in my life than in my destruction . <END> Often , when wearied by a toilsome march , I persuaded myself that I was dreaming until night should come and that I should then enjoy reality in the arms of my dearest friends . <END> More than once the agitation into which these reflections threw me made my friends dread a dangerous relapse . <END> \" How kind and generous you are ! <END> This passion is detrimental to me , for you do not reflect that YOU are'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.random_text(500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
